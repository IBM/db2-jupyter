{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing JSON Documents in Db2\n",
    "Updated: 2019-09-14\n",
    "\n",
    "This notebook describes the ways that JSON can be stored inside a Db2 database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing JSON Documents in a Relational Database\n",
    "The ISO standard does not specify how JSON documents should be stored in relational databases, leaving that decision to the database vendors. Since JSON can be easily stored in either its native character format or in the binary format (BSON) using existing database data types, most database products, including Db2, have chosen to not implement a native JSON data type.\n",
    "\n",
    "One prerequisite for storing JSON in its character form is that must be encoded in Unicode with the default Db2 encoding being UTF-8.\n",
    "\n",
    "Db2 provides several data type options for both JSON formats and the DBA can decide based on their individual needs. Some of the factors to consider when choosing a database data type are:\n",
    "\n",
    "* whether the original source data is in JSON or BSON format\n",
    "* whether the desired column data type is supported for the table type chosen\n",
    "* whether the maximum data length is compatible with the data type\n",
    "* whether query performance is a critical success factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing JSON as Character Strings\n",
    "JSON is convenient for developers for a number of reasons including the fact that JSON is in a \"readable\" format since it is just a character string. The data is presented in a form that doesn't require any conversion or formatting of the data to make sense of it. This makes the process of interchanging the data without other applications and systems much simpler and convenient for developers.\n",
    "\n",
    "The whitespace (blanks) found in JSON documents are ignored. This allows a developer to format the record in a way that makes it easy to read and understand its structure. Indentation and spacing are used for formatting and clarifying the structure of the record for similar reasons. There is no requirement in JSON itself for this extraneous formatting, it is strictly for the benefit of the human eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary JSON (BSON)\n",
    "There are drawbacks associated with representing JSON as human-readable strings. The storage required for any additional white-space and spacing can add up when dealing with millions of records. Searching for values in JSON records requires traversing throughout the document and parsing every value encountered. The overhead of hundreds of users searching millions of documents can quickly add up.\n",
    "\n",
    "In order to improve the access time to individual fields and values within a JSON document, vendors have developed alternative storage formats for the data. One popular format is called BSON which stands for Binary (JSON) storage notation. There are code libraries available for most programming languages which will convert JSON into the more efficient BSON format.\n",
    "\n",
    "While BSON has some slight space advantages over JSON (but not always), this format has a considerable advantage when it comes to searching within documents. The document is parsed into an internal format which allows for the efficient traversal of the fields and values. The overhead of converting a document to BSON can be quickly recovered when searching for fields within a large document. \n",
    "\n",
    "From a development perspective, JSON is the record structure that is being stored and manipulated whether it is stored in human-readable format or stored in a binary BSON form. From a processing perspective, BSON is the format typically used when query performance is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character versus Binary JSON\n",
    "Since JSON can be stored in character format or in binary format (BSON), the decision for which one to use is left up to the user. BSON has some slight space and compute advantages over JSON, but given the advanced compression capabilities of Db2, there is not much benefit gained from space savings.\n",
    "\n",
    "One reason to use BSON is for compatibility with existing applications that already create BSON objects. The JSON functions can determine from the data type which format the data is in and adjust the processing as required. This means that from a development perspective, there is no need to convert from JSON to BSON (or vice-versa) to use the JSON functions.\n",
    "\n",
    "BSON is supported within Db2 in two ways. The data that is inserted into a column can be converted to BSON using the built-in **`BSON_TO_JSON`** function or the application can use any routines that convert character strings into the proper BSON format. The BSON format used by the earlier Db2 JSON API functions is supported in addition to the new format. Applications that were written using the JSON API BSON format can use this new set of JSON functions without converting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some restrictions to what the BSON document can contain within it. The following table summarizes the BSON data types that are supported by Db2.\n",
    " \n",
    "| BSON ID  | TYPE \n",
    "|--------: |:-----\n",
    "| 1 | Double               \n",
    "| 2 | String               \n",
    "| 3 | Object               \n",
    "| 4 | Array                \n",
    "| 8 | Boolean              \n",
    "| 9 | Date                 \n",
    "|10 | Null      \n",
    "|16 | 32-bit integer\n",
    "|18 | 64-bit integer\n",
    "\n",
    "Any BSON types outside of these values will not be recognized during processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample JSON Data Set\n",
    "The examples found in this chapter use a JSON data set (customers.js) that needs ro be generated. A sample document is found below:\n",
    "```json\n",
    "{\n",
    "    \"customerid\": 100000,\n",
    "    \"identity\": \n",
    "      {\n",
    "        \"firstname\": \"Jacob\", \"lastname\": \"Hines\", \n",
    "        \"birthdate\": \"1982-09-18\"\n",
    "      },\n",
    "    \"contact\": \n",
    "      {\n",
    "        \"street\": \"Main Street North\",\n",
    "        \"city\": \"Amherst\", \"state\": \"OH\", \"zipcode\": \"44001\",\n",
    "        \"email\": \"Ja.Hines@yahii.com\",\n",
    "        \"phone\": \"813-689-8309\"\n",
    "      },\n",
    "    \"payment\": \n",
    "      {\n",
    "        \"card_type\": \"MCCD\", \"card_no\": \"4742-3005-2829-9227\"\n",
    "      },\n",
    "    \"purchases\": \n",
    "    [\n",
    "      {\n",
    "        \"tx_date\": \"2018-02-14\",\n",
    "        \"tx_no\": 157972,\n",
    "        \"product_id\": 1860,\n",
    "        \"product\": \"Ugliest Snow Blower\",\n",
    "        \"quantity\": 1,\n",
    "        \"item_cost\": 51.8\n",
    "      }, ... additional purchases ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The JSON document contains five distinct pieces of information:\n",
    "* Customerid – Primary key\n",
    "* Identity – Information on the customer including name and birthdate\n",
    "* Contact – Address, email, and phone number information\n",
    "* Payment – Current payment card that is used\n",
    "* Purchase – The purchase that the customer has made\n",
    "\n",
    "The purchase structure contains information on the customer purchases. For each purchased item, there is the following information:\n",
    "* tx_date – Date of the transaction\n",
    "* tx_no – Transaction number\n",
    "* product_id – Id for the product\n",
    "* product – Name of the product\n",
    "* quantity – Quantity of products purchased\n",
    "* item_cost – Cost of one product\n",
    "\n",
    "If this was a relational database, you would probably split these fields up into different tables and use join techniques to bring the information back together. In a JSON document, we are able to keep all of this information in one place, which makes retrieval of an individual customer's purchases easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Db2 Extensions and Connect to the Database\n",
    "The `connection` notebook contains the `CONNECT` statement which allows access to the `SAMPLE` database. If you need to modify the connection information, edit the `connection.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../db2.ipynb\n",
    "%run ../connection.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Customer File\n",
    "The following code will generate 25000 customers records formatted as JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run generate_json.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Table with Character JSON Columns\n",
    "JSON data can be stored in any column that is defined as a character data type. The format of the table can be either ROW organized, or COLUMN organized. In the case of `COLUMN ORGANIZED` tables, the CLOB column data type is only supported in Db2 11.5.\n",
    "\n",
    "The following SQL demonstrates the various ways a JSON character column can be defined in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -quiet\n",
    "DROP TABLE JSON_DATA;\n",
    "CREATE TABLE JSON_DATA \n",
    "  \n",
    "    FIELD1 CHAR(255),\n",
    "    FIELD2 VARCHAR(300),\n",
    "    FIELD3 CLOB(1000)\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a CLOB object, an `INLINE LENGTH` specification should be used to try and place as much of the data on the data page to take advantage of the performance advantage provided by the buffer pool caching effect. If you do not specify an inline length for CLOB objects, the JSON data will not reside in the buffer pool and searching and retrieval of this data will take an additional I/O operation.\n",
    "The following SQL will recreate the JSON_DATA table specifying an inline length for the JSON column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -quiet\n",
    "DROP TABLE JSON_DATA;\n",
    "CREATE TABLE JSON_DATA \n",
    "  (\n",
    "    JSON CLOB(1000) INLINE LENGTH 1000\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideration should also be given to using a large enough table page size (32K) so that it all of the JSON data can be stored on it. \n",
    "\n",
    "**Note:** To use the Db2 JSON SYSTOOLS functions, you must store the data as BSON in BLOB objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Table with Binary JSON (BSON) Columns\n",
    "BSON data can be stored in columns defined as a binary data type which encompasses the `BINARY`, `VARBINARY`, and `BLOB` data types. There is one additional binary data type that is supported, `FOR BIT DATA` character columns. With the introduction of `BINARY` and `VARBINARY` fields, there is little reason to use the `FOR BIT DATA` specification. In the case of `COLUMN ORGANIZED` tables, the `BLOB` column data type is only supported in Db2 11.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -quiet\n",
    "DROP TABLE JSON_DATA;\n",
    "CREATE TABLE JSON_DATA \n",
    "  (\n",
    "    FIELD1 BINARY(255),\n",
    "    FIELD2 VARBINARY(300),\n",
    "    FIELD3 BLOB(1000),\n",
    "    FIELD4 VARCHAR(300) FOR BIT DATA\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a BLOB column, the same considerations mentioned for CLOB columns in the previous section also apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between JSON and BSON Storage\n",
    "There are a number of considerations when choosing BSON over JSON. Using BSON can result in spacing savings (most of the time!) but requires extra processing power to convert the JSON character strings. To illustrate the space savings, the following example will use the customer.js file created earlier in this script.\n",
    "\n",
    "The customer file (customer.js) contains a single row for each JSON record similar to the following:\n",
    "```json\n",
    "{\"customerid\": 100000, \"identity\": {\"firstname\": \"Jonathan\",...\n",
    "```\n",
    "Rather than having to write an application to read and insert the data, the Db2 IMPORT command can be used to insert this data in one step.\n",
    "```sql\n",
    "CREATE TABLE JSON_RAW_DATA \n",
    "  (\n",
    "  CUSTOMER VARCHAR(2000)\n",
    "  );\n",
    "IMPORT FROM customers.js OF ASC METHOD l(1 2000) \n",
    "    INSERT INTO JSON_RAW_DATA;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Customer file into a table\n",
    "You must run the first command to get the working directory for the IMPORT command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = os.getcwd() + \"/customers.js\"\n",
    "print(\"Input file: \" + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the table that will contain the customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -quiet \n",
    "DROP TABLE JSON_RAW_DATA;\n",
    "CREATE TABLE JSON_RAW_DATA \n",
    "  (\n",
    "  CUSTOMER VARCHAR(2000)\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Db2 following code will be used to load the data into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "print(\"Starting Load\")\n",
    "start_time = time.time()\n",
    "%sql autocommit off\n",
    "x = %sql prepare INSERT INTO JSON_RAW_DATA VALUES (?)\n",
    "if (x != False):\n",
    "    i = 0\n",
    "    with open(fname,\"r\") as records:\n",
    "        for record in records:\n",
    "            i += 1\n",
    "            rc = %sql execute :x using record@char\n",
    "            if (rc == False): break\n",
    "            if ((i % 5000) == 0): \n",
    "                print(str(i)+\" rows read.\")\n",
    "                %sql commit hold\n",
    "                \n",
    "    %sql commit work  \n",
    "%sql autocommit on\n",
    "end_time = time.time()\n",
    "print('Total load time for {:d} records is {:.2f} seconds'.format(i,end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will create two tables to hold the data: one using a character format, while the second one using a binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql -q\n",
    "DROP TABLE JSON_CHAR;\n",
    "CREATE TABLE JSON_CHAR \n",
    "  (\n",
    "    CUSTOMER VARCHAR(2000)\n",
    "  );\n",
    "    \n",
    "DROP TABLE JSON_BINARY;\n",
    "CREATE TABLE JSON_BINARY \n",
    "  (\n",
    "    CUSTOMER VARBINARY(2000)\n",
    "  );\n",
    "DROP TABLE CUSTOMERS;\n",
    "CREATE TABLE CUSTOMERS\n",
    "  (\n",
    "  INFO VARCHAR(2000)\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the base table will be inserted into these two tables using `INSERT INTO SELECT FROM` syntax. The size of each table is compared after the INSERT completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql -q INSERT INTO CUSTOMERS SELECT * FROM JSON_RAW_DATA;\n",
    "%sql -q INSERT INTO JSON_CHAR SELECT * FROM JSON_RAW_DATA;\n",
    "char_load = sqlelapsed\n",
    "%sql -q INSERT INTO JSON_BINARY SELECT JSON_TO_BSON(CUSTOMER) FROM JSON_RAW_DATA;\n",
    "blob_load = sqlelapsed\n",
    "char_size = %sql -r SELECT SUM(LENGTH(CUSTOMER)) FROM JSON_CHAR\n",
    "blob_size = %sql -r SELECT SUM(LENGTH(CUSTOMER)) FROM JSON_BINARY\n",
    "%sql -bar values ('CHAR',:char_size[1]),('BLOB',:blob_size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in storage is minimal but generally the size of a BSON table will be about 5% less than a character based table. Converting JSON data to BSON does incur some additional overhead so that may also be a consideration when storing the data. The execution time was captured from the previous `INSERT` statements and is summarized in the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql -bar values ('CHAR',:char_load),('BLOB',:blob_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the data to BSON does add overhead to the `INSERT` time. If you are only storing and retrieving entire JSON documents then the conversion to BSON may not be unnecessary. However, if you find that you are continually quering these documents then the overhead of converting to BSON will be worth the improved query time. BSON has an internal tree structure that makes querying document much more efficient, while character-based JSON objects will first need to be converted to BSON before any searching can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "JSON data can be stored in character or binary format. The decision of which format to use is left up to the DBA and the Db2 functions can work against either format. Consideration should be given to storing documents in BSON format if the contents of the document are to queried. While BSON has a slight advantage of space savings over character-based JSON documents, it does incur added overhead during the conversion process. However, this additional overhead is easily justified with the improved performance when searching within a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019, George Baklarz [baklarz@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
